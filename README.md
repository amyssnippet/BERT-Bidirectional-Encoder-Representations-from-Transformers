# BERT: Bidirectional Encoder Representations from Transformers

**This github contains code for [BERT: Bidirectional Encoder Representations from Transformers](https://learnopencv.com/bert-bidirectional-encoder-representations-from-transformers/) - Unlocking the Power of Deep Contextualized Word Embeddings blogpost**.

![](media/bert-masked-language-modeling.png)

Download the Jupyter notebooks and the trained model using the following link.

[<img src="https://learnopencv.com/wp-content/uploads/2022/07/download-button-e1657285155454.png" alt="download" width="200">](https://www.dropbox.com/scl/fo/emu04jitxcme3kfaj9rer/h?rlkey=onq61ypfttgclc2drkmvi1czr&dl=1)
